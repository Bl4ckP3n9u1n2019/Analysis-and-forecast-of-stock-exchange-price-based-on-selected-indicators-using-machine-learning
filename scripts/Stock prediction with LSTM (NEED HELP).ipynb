{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model prediction (NEED YOUR HELP)Â¶\n",
    "https://www.analyticsvidhya.com/blog/2018/10/predicting-stock-price-machine-learningnd-deep-learning-techniques-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import pyodbc\n",
    "import datetime\n",
    "import plotly.express as px\n",
    "import sqlite3\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Destination folder (comment unused directory)\n",
    "#1 \n",
    "os.chdir(\"C:/Users/Lukasz/Documents/GitHub/Analysis-and-forecast-of-stock-exchange-price-based-on-selected-indicators-using-machine-learning/data\")\n",
    "#2\n",
    "#os.chdir(\"F:/GitHub/Analysis-and-forecast-of-stock-exchange-price-based-on-selected-indicators-using-machine-learning/data\")\n",
    "\n",
    "# Create your connection.\n",
    "conn = sqlite3.connect('predictions.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Covid19</th>\n",
       "      <th>Crude_Oil</th>\n",
       "      <th>Copper</th>\n",
       "      <th>Silver</th>\n",
       "      <th>Platinum</th>\n",
       "      <th>Industrial_Production</th>\n",
       "      <th>Palladium</th>\n",
       "      <th>SP500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2510</td>\n",
       "      <td>2020-03-25 00:00:00</td>\n",
       "      <td>416881.0</td>\n",
       "      <td>24.49</td>\n",
       "      <td>2.2040</td>\n",
       "      <td>13.965</td>\n",
       "      <td>745.50</td>\n",
       "      <td>103.664</td>\n",
       "      <td>2247.6</td>\n",
       "      <td>2475.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2511</td>\n",
       "      <td>2020-03-26 00:00:00</td>\n",
       "      <td>468092.0</td>\n",
       "      <td>22.60</td>\n",
       "      <td>2.1780</td>\n",
       "      <td>14.415</td>\n",
       "      <td>737.10</td>\n",
       "      <td>103.664</td>\n",
       "      <td>2226.1</td>\n",
       "      <td>2630.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2512</td>\n",
       "      <td>2020-03-27 00:00:00</td>\n",
       "      <td>527839.0</td>\n",
       "      <td>21.51</td>\n",
       "      <td>2.1720</td>\n",
       "      <td>14.315</td>\n",
       "      <td>740.82</td>\n",
       "      <td>103.664</td>\n",
       "      <td>2196.8</td>\n",
       "      <td>2541.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2513</td>\n",
       "      <td>2020-03-30 00:00:00</td>\n",
       "      <td>715377.0</td>\n",
       "      <td>20.09</td>\n",
       "      <td>2.1555</td>\n",
       "      <td>14.055</td>\n",
       "      <td>723.84</td>\n",
       "      <td>103.664</td>\n",
       "      <td>2197.6</td>\n",
       "      <td>2626.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2514</td>\n",
       "      <td>2020-03-31 00:00:00</td>\n",
       "      <td>777187.0</td>\n",
       "      <td>20.48</td>\n",
       "      <td>2.2280</td>\n",
       "      <td>13.930</td>\n",
       "      <td>728.80</td>\n",
       "      <td>103.664</td>\n",
       "      <td>2304.8</td>\n",
       "      <td>2584.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Date   Covid19  Crude_Oil  Copper  Silver  Platinum  \\\n",
       "2510  2020-03-25 00:00:00  416881.0      24.49  2.2040  13.965    745.50   \n",
       "2511  2020-03-26 00:00:00  468092.0      22.60  2.1780  14.415    737.10   \n",
       "2512  2020-03-27 00:00:00  527839.0      21.51  2.1720  14.315    740.82   \n",
       "2513  2020-03-30 00:00:00  715377.0      20.09  2.1555  14.055    723.84   \n",
       "2514  2020-03-31 00:00:00  777187.0      20.48  2.2280  13.930    728.80   \n",
       "\n",
       "      Industrial_Production  Palladium    SP500  \n",
       "2510                103.664     2247.6  2475.56  \n",
       "2511                103.664     2226.1  2630.07  \n",
       "2512                103.664     2196.8  2541.47  \n",
       "2513                103.664     2197.6  2626.65  \n",
       "2514                103.664     2304.8  2584.59  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicator=\"SP500\"\n",
    "#Get SQLLite select statement for SP500 index and indicators\n",
    "df = pd.read_sql_query(\"\"\"select x.\"Date\", c19.\"Index\" Covid19, co.\"Index\" as Crude_Oil, \n",
    "cr.\"Index\" as Copper, s.\"Index\" as Silver, p.\"Index\" as Platinum,\n",
    "ip.\"Index\" as Industrial_Production, pa.\"Index\" as Palladium, x.\"Index\" as \"\"\"+indicator+\"\"\"\n",
    " from \"\"\"+indicator+\"\"\" as x\n",
    "  LEFT OUTER JOIN Covid19 as c19 ON x.Date = C19.Date\n",
    "  LEFT OUTER JOIN Crude_Oil as co ON x.Date=co.Date\n",
    "  LEFT OUTER JOIN Copper as cr ON x.Date=cr.Date\n",
    "  LEFT OUTER JOIN Silver as s ON x.Date=s.Date\n",
    "  LEFT OUTER JOIN Platinum as p ON x.Date=p.Date\n",
    "  LEFT OUTER JOIN Industrial_Prod as ip ON strftime('%Y-%m', x.Date)=strftime('%Y-%m', ip.Date)\n",
    "  LEFT OUTER JOIN Palladium as pa ON x.Date=pa.Date\n",
    "Where x.\"Index\" and co.\"Index\" and cr.\"Index\" and s.\"Index\" and p.\"Index\"\n",
    "and ip.\"Index\" and pa.\"Index\" IS NOT NULL\n",
    "and x.Date < '2020-04-01'\n",
    "\"\"\", conn)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting index\n",
    "df.index = df.Date\n",
    "df.drop('Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating train and test sets\n",
    "dataset = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset[0:987,:]\n",
    "valid = dataset[987:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting dataset into x_train and y_train\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = [], []\n",
    "for i in range(60,len(train)):\n",
    "    x_train.append(scaled_data[i-60:i,0])\n",
    "    y_train.append(scaled_data[i,0])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 116s - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x92859cca08>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1],1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty table with 12 fields\n",
    "trainPredict_dataset_like = np.zeros(shape=(len(train_predict), 12) )\n",
    "# put the predicted values in the right field\n",
    "trainPredict_dataset_like[:,0] = trainPredict[:,0]\n",
    "# inverse transform and then select the right field\n",
    "trainPredict = scaler.inverse_transform(trainPredict_dataset_like)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (12704,1) doesn't match the broadcast shape (12704,8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-00ef7f5fb9c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0minputs\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    387\u001b[0m                         force_all_finite=\"allow-nan\")\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: non-broadcastable output operand with shape (12704,1) doesn't match the broadcast shape (12704,8)"
     ]
    }
   ],
   "source": [
    "#predicting 246 values, using past 60 from the train data\n",
    "inputs = df[len(df) - len(valid) - 60:].values\n",
    "inputs = inputs.reshape(-1,1)\n",
    "inputs  = scaler.transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for i in range(60,inputs.shape[0]):\n",
    "    X_test.append(inputs[i-60:i,0])\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
    "closing_price = model.predict(X_test)\n",
    "closing_price = scaler.inverse_transform(closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms=np.sqrt(np.mean(np.power((valid-closing_price),2)))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for plotting\n",
    "train = new_data[:987]\n",
    "valid = new_data[987:]\n",
    "valid['Predictions'] = closing_price\n",
    "plt.plot(train['Close'])\n",
    "plt.plot(valid[['Close','Predictions']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
